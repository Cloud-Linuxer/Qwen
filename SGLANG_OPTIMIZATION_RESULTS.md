# SGLang RTX 5090 ìµœì í™” ê²°ê³¼ ë³´ê³ ì„œ

## ğŸ“Š ìµœì í™” ì„±ëŠ¥ ë¹„êµ ê²°ê³¼

### 1. í…ŒìŠ¤íŠ¸ í™˜ê²½
- **í•˜ë“œì›¨ì–´**: NVIDIA RTX 5090 (32GB VRAM, Blackwell sm_120)
- **ëª¨ë¸**: Qwen3-32B-AWQ (4-bit ì–‘ìí™”)
- **í”„ë ˆì„ì›Œí¬**: SGLang v0.3.9.post2
- **í…ŒìŠ¤íŠ¸ ì¼ì**: 2025ë…„ 9ì›” 16ì¼

### 2. ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼

| êµ¬ì„± | ì‘ë‹µ ì§€ì—° | ì²˜ë¦¬ ì†ë„ | TTFT | GPU ë©”ëª¨ë¦¬ | ì•ˆì •ì„± |
|------|---------|-----------|------|----------|--------|
| **Baseline (Triton)** | 1049ms | 10.2 tok/s | 283ms | 20.9GB | âœ… ì•ˆì • |
| **Ultra-Optimized** | 1049ms | 10.17 tok/s | 283ms | 20.9GB | âœ… ì•ˆì • |
| **Balanced-v2** | **978ms** â¬†ï¸ | **10.27 tok/s** â¬†ï¸ | **195ms** â¬†ï¸ | 21.1GB | âœ… ì•ˆì • |
| **Experimental** | - | - | - | - | âŒ ì‹¤íŒ¨ |

### 3. ìµœì í™” êµ¬ì„± ë¹„êµ

#### Baseline (ì´ˆê¸° ìµœì í™”)
```bash
--attention-backend triton
--sampling-backend pytorch
--max-total-tokens 3072
--mem-fraction-static 0.85
--disable-cuda-graph
--disable-custom-all-reduce
--disable-flashinfer
--disable-radix-cache
```
**ê²°ê³¼**: ì•ˆì •ì ì¸ ê¸°ì¤€ ì„±ëŠ¥ (10.2 tok/s)

#### Ultra-Optimized (ì¶”ê°€ ìµœì í™”)
```bash
# Baseline + ì¶”ê°€:
--enable-torch-compile
--torch-compile-max-bs 8
--schedule-policy lpm
--num-continuous-decode-steps 3
--triton-attention-reduce-in-fp32
--triton-attention-num-kv-splits 16
```
**ê²°ê³¼**: Torch Compile íš¨ê³¼ ë¯¸ë¯¸, ì„±ëŠ¥ ê±°ì˜ ë™ì¼

#### Balanced-v2 (ê· í˜• ìµœì í™”) â­ **ìµœê³  ì„±ëŠ¥**
```bash
# Baseline + ì¶”ê°€:
--enable-torch-compile
--torch-compile-max-bs 6
--schedule-policy lof  # Least Outstanding First
--num-continuous-decode-steps 2
--triton-attention-num-kv-splits 12
--allow-auto-truncate
--mem-fraction-static 0.87
```
**ê²°ê³¼**:
- ì‘ë‹µ ì§€ì—° **7% ê°œì„ ** (1049ms â†’ 978ms)
- TTFT **31% ê°œì„ ** (283ms â†’ 195ms)
- ì²˜ë¦¬ ì†ë„ ì†Œí­ ê°œì„  (10.27 tok/s)

#### Experimental (ì‹¤í—˜ì  ìµœì í™”)
```bash
# ì‹œë„í–ˆì§€ë§Œ ì‹¤íŒ¨:
--cuda-graph-max-bs 4
--cuda-graph-bs 1 2 4
--enable-hierarchical-cache
--enable-mixed-chunk
--enable-two-batch-overlap
--schedule-policy dfs-weight
```
**ê²°ê³¼**: Blackwell ì•„í‚¤í…ì²˜ì™€ í˜¸í™˜ì„± ë¬¸ì œë¡œ ì‹¤íŒ¨

### 4. ì£¼ìš” ë°œê²¬ì‚¬í•­

#### âœ… íš¨ê³¼ì ì¸ ìµœì í™”
1. **LOF ìŠ¤ì¼€ì¤„ë§ ì •ì±…**: ì‘ë‹µ ì§€ì—° 7% ê°œì„ 
2. **ì ì ˆí•œ ì—°ì† ë””ì½”ë“œ ìŠ¤í… (2)**: TTFT 31% ê°œì„ 
3. **ë©”ëª¨ë¦¬ í• ë‹¹ 87%**: ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•
4. **Triton KV ë¶„í•  12**: ìµœì ì˜ ë¶„í•  ì„¤ì •

#### âŒ íš¨ê³¼ ì—†ê±°ë‚˜ ë¬¸ì œ ìˆëŠ” ìµœì í™”
1. **CUDA Graphs**: Blackwellì—ì„œ segmentation fault
2. **FP8 KV Cache**: OOM ì—ëŸ¬ ë°œìƒ
3. **LPM ìŠ¤ì¼€ì¤„ë§**: LOFë³´ë‹¤ ì„±ëŠ¥ ë‚®ìŒ
4. **ê³¼ë„í•œ ì—°ì† ë””ì½”ë“œ ìŠ¤í… (3+)**: ì˜¤íˆë ¤ ì„±ëŠ¥ ì €í•˜
5. **FlashInfer**: Blackwell sm_120ê³¼ í˜¸í™˜ ì•ˆ ë¨
6. **ê³„ì¸µì  ìºì‹œ**: ë©”ëª¨ë¦¬ ì˜¤ë²„í—¤ë“œë§Œ ì¦ê°€

### 5. ìµœì¢… ê¶Œì¥ êµ¬ì„±

```bash
docker run -d \
  --name sglang-optimized \
  --runtime nvidia \
  --gpus all \
  -p 8000:8000 \
  -v ~/.cache/huggingface:/root/.cache/huggingface \
  -e PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True,max_split_size_mb:256" \
  -e CUDA_LAUNCH_BLOCKING=0 \
  -e OMP_NUM_THREADS=10 \
  -e TORCH_CUDA_ARCH_LIST="9.0;12.0+PTX" \
  --shm-size 40g \
  sglang:blackwell-final-v2 \
  --model-path Qwen/Qwen3-32B-AWQ \
  --host 0.0.0.0 \
  --port 8000 \
  --quantization awq \
  --max-total-tokens 3328 \
  --max-prefill-tokens 1664 \
  --chunked-prefill-size 1152 \
  --mem-fraction-static 0.87 \
  --trust-remote-code \
  --attention-backend triton \
  --sampling-backend pytorch \
  --schedule-policy lof \
  --enable-torch-compile \
  --torch-compile-max-bs 6 \
  --num-continuous-decode-steps 2 \
  --triton-attention-reduce-in-fp32 \
  --triton-attention-num-kv-splits 12 \
  --disable-cuda-graph \
  --disable-custom-all-reduce \
  --disable-flashinfer \
  --decode-log-interval 30 \
  --stream-output \
  --allow-auto-truncate
```

### 6. ì„±ëŠ¥ ê°œì„  ìš”ì•½

**Baseline ëŒ€ë¹„ Balanced-v2 ê°œì„ :**
- ğŸš€ **ì‘ë‹µ ì†ë„**: 7% ë¹¨ë¼ì§ (1049ms â†’ 978ms)
- âš¡ **ì²« í† í° ì‹œê°„**: 31% ë¹¨ë¼ì§ (283ms â†’ 195ms)
- ğŸ“ˆ **ì²˜ë¦¬ëŸ‰**: ì†Œí­ ê°œì„  (10.2 â†’ 10.27 tok/s)
- ğŸ’¾ **ë©”ëª¨ë¦¬ ì‚¬ìš©**: ê±°ì˜ ë™ì¼ (20.9GB â†’ 21.1GB)
- âœ… **ì•ˆì •ì„±**: ë™ì¼í•˜ê²Œ ì•ˆì •ì 

### 7. Blackwell (RTX 5090) íŠ¹ì´ì‚¬í•­

1. **CUDA Graphs ë¹„í˜¸í™˜**: sm_120ì—ì„œ ì‘ë™ ì•ˆ í•¨
2. **FlashInfer ë¹„í˜¸í™˜**: Blackwell ì§€ì› ì—†ìŒ
3. **Custom All-Reduce ë¶ˆì•ˆì •**: ë¹„í™œì„±í™” í•„ìš”
4. **AWQ_Marlin ë¶ˆê°€**: ë©”ëª¨ë¦¬ ë¶€ì¡±
5. **Radix Cache ì„±ëŠ¥ ì €í•˜**: ë¹„í™œì„±í™” ê¶Œì¥

### 8. ê²°ë¡ 

RTX 5090 Blackwell ì•„í‚¤í…ì²˜ì—ì„œ SGLang ìµœì í™”ë¥¼ í†µí•´:
- **LOF ìŠ¤ì¼€ì¤„ë§**ê³¼ **ì ì ˆí•œ ì—°ì† ë””ì½”ë“œ ìŠ¤í…(2)**ì´ ê°€ì¥ íš¨ê³¼ì 
- **Torch Compile**ì€ ë°˜ë³µ ì‹¤í–‰ ì‹œ ì•½ê°„ì˜ ê°œì„  ì œê³µ
- ë§ì€ ê³ ê¸‰ ìµœì í™” ê¸°ëŠ¥ë“¤ì´ Blackwellê³¼ í˜¸í™˜ì„± ë¬¸ì œ ìˆìŒ
- **Balanced-v2 êµ¬ì„±**ì´ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì˜ ìµœì  ê· í˜•ì 

**ìµœì¢… ë‹¬ì„± ì„±ëŠ¥**:
- 10.27 tok/s ì²˜ë¦¬ëŸ‰
- 978ms í‰ê·  ì‘ë‹µ ì‹œê°„
- 195ms TTFT
- ì•ˆì •ì ì¸ ìš´ì˜ ê°€ëŠ¥