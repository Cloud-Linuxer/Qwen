#!/bin/bash
# SGLang ê°„ë‹¨ ë°°í¬ - Qwen3-32B-AWQ

set -e

echo "=== SGLang AWQ ëª¨ë¸ ë°°í¬ ==="
echo

# ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
echo "ðŸ§¹ ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬..."
docker ps -aq --filter "name=sglang" | xargs -r docker stop 2>/dev/null || true
docker ps -aq --filter "name=sglang" | xargs -r docker rm 2>/dev/null || true

# Docker Compose ìƒì„±
cat > docker-compose.sglang-awq.yml << 'EOF'
services:
  sglang-awq:
    image: lmsysorg/sglang:latest
    container_name: sglang-qwen-awq
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      - "127.0.0.1:8000:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ./models:/models
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - HF_TOKEN=${HF_TOKEN:-}
      # RTX 5090 workaround
      - TORCH_CUDA_ARCH_LIST=7.0;7.5;8.0;8.6;8.9;9.0+PTX
      - CUDA_LAUNCH_BLOCKING=0
    command:
      - --model-path=Qwen/Qwen3-32B-AWQ
      - --host=0.0.0.0
      - --port=8000
      - --dtype=half
      - --quantization=awq_marlin
      - --max-total-tokens=16384
      - --mem-fraction-static=0.95
      - --trust-remote-code
      - --disable-cuda-graph
      - --disable-custom-all-reduce
    restart: unless-stopped
    shm_size: '32gb'

networks:
  default:
    name: sglang-net
EOF

echo "ðŸš€ ì„œë²„ ì‹œìž‘..."
docker compose -f docker-compose.sglang-awq.yml up -d

echo "â³ ëª¨ë¸ ë¡œë”© ëŒ€ê¸°..."
sleep 10

echo "ðŸ“‹ ë¡œê·¸ í™•ì¸:"
docker compose -f docker-compose.sglang-awq.yml logs --tail=50

echo
echo "âœ… ë°°í¬ ì‹œë„ ì™„ë£Œ"
echo "ëª…ë ¹ì–´:"
echo "  ë¡œê·¸: docker compose -f docker-compose.sglang-awq.yml logs -f"
echo "  ì¤‘ì§€: docker compose -f docker-compose.sglang-awq.yml down"