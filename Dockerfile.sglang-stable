# SGLang Stable Build for RTX 5090 with PyTorch 2.7.0
FROM nvidia/cuda:12.8.0-cudnn-devel-ubuntu22.04

# System dependencies with debugging tools
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3.11-venv \
    python3-pip \
    git \
    wget \
    curl \
    build-essential \
    cmake \
    ninja-build \
    pkg-config \
    libnuma-dev \
    libnuma1 \
    gdb \
    strace \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.11 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1 && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1

# Upgrade pip
RUN python -m pip install --upgrade pip setuptools wheel ninja

# CRITICAL: Pin exact PyTorch version
RUN pip install --no-cache-dir \
    torch==2.7.0+cu128 \
    torchvision==0.20.0+cu128 \
    torchaudio==2.7.0+cu128 \
    --index-url https://download.pytorch.org/whl/cu128

# Install build dependencies
RUN pip install --no-cache-dir \
    packaging==24.0 \
    numpy==1.26.4 \
    pybind11==2.11.1 \
    cmake==3.28.1 \
    ninja==1.11.1.1

# Set CUDA architecture flags
ENV TORCH_CUDA_ARCH_LIST="8.0;8.6;8.9;9.0;12.0+PTX"
ENV CUDA_ARCHITECTURES="80;86;89;90;120"
ENV NVCC_PREPEND_FLAGS="-ccbin g++"
ENV CUDA_HOME=/usr/local/cuda
ENV PATH="${CUDA_HOME}/bin:${PATH}"
ENV LD_LIBRARY_PATH="${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}"

# Build settings
ENV FORCE_CUDA=1
ENV MAX_JOBS=4
ENV TORCH_CUDA_ARCH_LIST="8.0;8.6;8.9;9.0;12.0+PTX"

# Clone and build SGLang with specific commit
WORKDIR /build
RUN git clone https://github.com/sgl-project/sglang.git && \
    cd sglang && \
    git checkout v0.3.7 && \
    git submodule update --init --recursive

# Install core dependencies first
RUN cd sglang && pip install --no-cache-dir \
    transformers==4.44.2 \
    accelerate==0.33.0 \
    requests==2.32.3 \
    pillow==10.4.0 \
    aiohttp==3.10.5 \
    fastapi==0.115.0 \
    uvicorn==0.30.6 \
    psutil==6.0.0 \
    protobuf==5.28.2 \
    sentencepiece==0.2.0

# Build and install sgl_kernel with error handling
WORKDIR /build/sglang/python
RUN python -m pip install -e . --verbose 2>&1 | tee /build/install.log && \
    python -c "import sgl_kernel; print(f'sgl_kernel version: {sgl_kernel.__version__}')" || \
    (echo "sgl_kernel build failed, checking logs..." && tail -100 /build/install.log && exit 1)

# Install AWQ support
RUN pip install --no-cache-dir autoawq==0.2.6

# Install Triton with specific version
RUN pip install --no-cache-dir triton==3.0.0

# NO FlashInfer - it's causing segfaults with Blackwell
# Instead, we'll use native attention or xformers

# Install xformers as alternative
RUN pip install --no-cache-dir xformers==0.0.28.post3 --index-url https://download.pytorch.org/whl/cu128

# RTX 5090 optimized settings
ENV CUDA_VISIBLE_DEVICES=0
ENV PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True,max_split_size_mb:512"
ENV CUDA_LAUNCH_BLOCKING=1  # Enable for debugging
ENV TORCH_USE_CUDA_DSA=1

# Verification script
RUN python -c "
import torch
import sys
print(f'PyTorch: {torch.__version__}')
print(f'CUDA: {torch.version.cuda}')
print(f'CUDA Available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')

# Test basic CUDA operations
try:
    x = torch.randn(100, 100).cuda()
    y = torch.matmul(x, x)
    torch.cuda.synchronize()
    print('Basic CUDA ops: OK')
except Exception as e:
    print(f'CUDA ops failed: {e}')
    sys.exit(1)

# Test sgl_kernel
try:
    import sgl_kernel
    print(f'sgl_kernel: OK')
except Exception as e:
    print(f'sgl_kernel import failed: {e}')
    sys.exit(1)
"

WORKDIR /app
EXPOSE 8000 8001

# Startup wrapper with debugging
RUN echo '#!/bin/bash\n\
set -e\n\
echo "=== SGLang Startup ==="\n\
echo "PyTorch version:"\n\
python -c "import torch; print(torch.__version__)"\n\
echo "CUDA devices:"\n\
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv\n\
echo "Starting server with args: $@"\n\
python -m sglang.launch_server "$@"\n\
' > /app/start.sh && chmod +x /app/start.sh

ENTRYPOINT ["/app/start.sh"]